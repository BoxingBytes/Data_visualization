geom_col(fill = "darkblue") +
geom_text(aes(label = round(avg_daily_val, 0)), vjust = -0.5, size = 3.5) +
scale_y_continuous(labels = scales::comma) +
labs(
title = "Average Traffic by Day of Week",
subtitle = "Excluding Holidays",
x = "Day",
y = "Average Validations"
) +
theme_minimal()
#GENERAL STATS
top_stations <- val_explore %>%
group_by(LIBELLE_ARRET) %>%
summarise(
total_validations = sum(NB_VALD, na.rm = TRUE),
avg_daily = mean(NB_VALD, na.rm = TRUE)
) %>%
arrange(desc(total_validations)) %>%
head(10)
ggplot(top_stations, aes(x = reorder(LIBELLE_ARRET, total_validations), y = total_validations)) +
geom_col(fill = "steelblue") +
coord_flip() +
scale_y_continuous(labels = scales::comma) +
labs(title = "Top 10 Busiest Stations", x = "", y = "Total Validations") +
theme_minimal()
library(readr)
library(dplyr)
library(ggplot2)
library(lubridate )
library(sf)
library(readr)
library(dplyr)
library(ggplot2)
library(lubridate )
library(sf)
col_spec <- cols(.default = "c")
val_2025_first <- read_csv2("data/validations-reseau-ferre-nombre-validations-par-jour-1er-trimestre.csv", col_types = col_spec)
val_2025_second <- read_csv2("data/validations-reseau-ferre-nombre-validations-par-jour-2eme-trimestre.csv", col_types = col_spec)
val_2018_first <- read_delim("data/data-rf-2018/2018_S1_NB_FER.txt", delim = "\t", col_types = col_spec)
val_2018_second <- read_delim("data/data-rf-2018/2018_S2_NB_FER.txt", delim = "\t",col_types = col_spec)
val_2019_first <- read_delim("data/data-rf-2019/2019_S1_NB_FER.txt", delim = "\t",col_types = col_spec)
val_2019_second <- read_delim("data/data-rf-2019/2019_S2_NB_FER.txt", delim = "\t",col_types = col_spec)
val_2020_first <- read_delim("data/data-rf-2020/2020_S1_NB_FER.txt", delim = "\t",col_types = col_spec)
val_2020_second <- read_delim("data/data-rf-2020/2020_S2_NB_FER.txt", delim = "\t",col_types = col_spec)
val_2021_first <- read_delim("data/data-rf-2021/2021_S1_NB_FER.txt", delim = "\t", col_types = col_spec)
val_2021_second <- read_delim("data/data-rf-2021/2021_S2_NB_FER.txt", delim = "\t", col_types = col_spec)
val_2022_first <- read_delim("data/data-rf-2022/2022_S1_NB_FER.txt", delim = "\t", col_types = col_spec)
val_2022_second <- read_delim("data/data-rf-2022/2022_S2_NB_FER.txt", delim = ";", col_types = col_spec)
val_2023_first <- read_delim("data/data-rf-2023/2023_S1_NB_FER.txt", delim = "\t", col_types = col_spec)
val_2023_second <- read_delim("data/data-rf-2023/2023_S2_NB_FER.txt", delim = "\t", locale = locale(encoding = "UTF-16"), col_types = col_spec)
val_2024_first <- read_delim("data/data-rf-2024/2024_S1_NB_FER.txt", delim = "\t", col_types = col_spec)
val_2025_second <- rename(val_2025_second, ID_REFA_LDA = ID_ZDC)
val_2025_first <- rename(val_2025_first, ID_REFA_LDA = ID_ZDC)
val_2023_second <- rename(val_2023_second, ID_REFA_LDA = ID_ZDC)
val_2023_first <- rename(val_2023_first, ID_REFA_LDA = lda)
val_2024_first <- rename(val_2024_first, ID_REFA_LDA = ID_ZDC)
val_2022_second <- rename(val_2022_second, ID_REFA_LDA = lda)
val_merged <- bind_rows(
val_2018_first,
val_2018_second,
val_2019_first,
val_2019_second,
val_2020_first,
val_2020_second,
val_2021_first,
val_2021_second,
val_2022_first,
val_2022_second,
val_2023_first,
val_2023_second,
val_2024_first,
val_2025_first,
val_2025_second
)
val_merged <- val_merged |> na.omit()
val_merged <- val_merged %>%
mutate(JOUR = parse_date_time(JOUR, orders = c("ymd", "mdy", "dmy")))
val_merged
names(val_merged)
val_merged
val_merged
zd_grouped <- zd %>%
group_by(idrefa_lda) %>%
summarise(geometry = st_union(geometry))
zd <- st_read("data/REF_ZdA/PL_ZDL_R_11-11-2025.shp" )
zd <- zd |> mutate(across(-geometry, as.character))
str(zd)
zd_grouped <- zd %>%
group_by(idrefa_lda) %>%
summarise(geometry = st_union(geometry))
val_zd <- left_join(val_merged, zd_grouped, by = c("ID_REFA_LDA" = "idrefa_lda"))
val_merged
val_merged
unique(val_merged$CATEGORIE_TITRE)
val_merged
install.packages("arrow")
library(arrow)
write_parquet(val_merged, "validations.parquet")
zd <- st_read("data/REF_ZdA/PL_ZDL_R_11-11-2025.shp" )
zd <- zd |> mutate(across(-geometry, as.character))
str(zd)
zd <- st_read("data/REF_ZdA/PL_ZDL_R_11-11-2025.shp" )
zd <- zd |> mutate(across(-geometry, as.character))
str(zd)
zd_grouped <- zd %>%
group_by(idrefa_lda) %>%
summarise(geometry = st_union(geometry))
val_merged
val_merged |> group_by('ID_REFA_LDA','JOUR','CATEGORIE_TITRE')
val_merged |> group_by(ID_REFA_LDA,JOUR,CATEGORIE_TITRE)
val_merged
val_merged |> group_by(ID_REFA_LDA,JOUR,CATEGORIE_TITRE)
val_merged |> group_by(ID_REFA_LDA,JOUR,CATEGORIE_TITRE) |> summarize(NB_VALD = sum(NB_VALD))
as.integer(val_merged$NB_VALD)
val_merged$NB_VALD = as.integer(val_merged$NB_VALD)
unique(val_merged$NB_VALD)
unique(val_merged$NB_VALD)
val_merged |> group_by(ID_REFA_LDA,JOUR,CATEGORIE_TITRE) |> summarize(NB_VALD = sum(NB_VALD))
val_merged |> arrange()
val_merged |> arrange(desc)
val_merged <- bind_rows(
val_2018_first,
val_2018_second,
val_2019_first,
val_2019_second,
val_2020_first,
val_2020_second,
val_2021_first,
val_2021_second,
val_2022_first,
val_2022_second,
val_2023_first,
val_2023_second,
val_2024_first,
val_2025_first,
val_2025_second
)
val_merged <- val_merged |> na.omit()
val_merged <- val_merged %>%
mutate(JOUR = parse_date_time(JOUR, orders = c("ymd", "mdy", "dmy")))
names(val_merged)
val_merged
val_merged$NB_VALD = as.integer(val_merged$NB_VALD)
unique(val_merged$NB_VALD)
val_merged |> group_by(ID_REFA_LDA,JOUR,CATEGORIE_TITRE) |> summarise(NB_VALD = sum(NB_VALD))
desc(val_merged$ID_REFA_LDA)
m
val_merged
val_grouped = val_merged |> group_by(ID_REFA_LDA,JOUR,CATEGORIE_TITRE) |> summarise(NB_VALD = sum(NB_VALD))
val_grouped
val_merged
val_grouped = val_merged |> group_by(ID_REFA_LDA,JOUR,CATEGORIE_TITRE, LIBELLE_ARRET) |> summarise(NB_VALD = sum(NB_VALD))
val_grouped
unique(val_merged$ID_REFA_LDA)
unique(val_grouped$ID_REFA_LDA)
val_grouped
val_merged
val_grouped = val_merged |> group_by(ID_REFA_LDA,JOUR,CATEGORIE_TITRE) |> summarise(NB_VALD = sum(NB_VALD))
val_grouped
write_parquet(val_grouped, "validations.parquet")
unique(val_merged$NB_VALD)
unique(val_merged$ID_REFA_LDA)
df <- df %>%
mutate(ID_REFA_LDA = sub("\\.0$", "", ID_REFA_LDA))
val_merged_cast <- val_merged %>% mutate(ID_REFA_LDA = sub("\\.0$", "", ID_REFA_LDA))
unique(val_merged$ID_REFA_LDA)
unique(val_merged_cast$ID_REFA_LDA)
unique(val_merged_cast$ID_REFA_LDA)
val_grouped = val_merged_cast |> group_by(ID_REFA_LDA,JOUR,CATEGORIE_TITRE) |> summarise(NB_VALD = sum(NB_VALD))
val_grouped
write_parquet(val_grouped, "validations.parquet")
zd <- st_read("data/REF_ZdA/PL_ZDL_R_11-11-2025.shp" )
unique(zd$type_arret)
names(zd)
zd_railway <- filter(idrefa_lda %in% unique_stations)
zd_railway = zd <- filter(idrefa_lda %in% unique_stations)
unique_stations = unique(zd$ID_REFA_LDA)
unique_stations = unique(zd$idrefa_lda)
names(zd)
zd_railway = zd <- filter(idrefa_lda %in% unique_stations)
unique_stations
zd_railway = zd %>% filter(idrefa_lda %in% unique_stations)
zd_railway
len(zd_railway)
length(zd_railway)
shape(zd_railway)
shp(zd_railway)
dim(zd_railway)
dim(zd)
zd <- st_read("data/REF_ZdA/PL_ZDL_R_11-11-2025.shp" )
dim(zd)
dim(unique_stations)
unique_stations = unique(zd$idrefa_lda)
dim(unique_stations)
unique_stations = unique(val_grouped$ID_REFA_LDA)
zd_railway = zd %>% filter(idrefa_lda %in% unique_stations)
dim(zd_railway)
dim(zd)
dim(unique_stations)
length(unique_stations)
dim(zd_railway)
#we just kept the railway stations
dim(zd_railway)
write_parquet(zd_railway, "railway.parquet")
zd_railway
st_write(zd_railway, "railway.parquet")
st_write(zd_railway, "railway.shp")
library(sfarrow)
install.packages(sfarrow)
install.packages("sfarrow")
zd_railway
st_write_parquet(zd_railway, "railway.parquet")
st_write(zd_railway, "railway.shp")
zd_railway
holidays <- as.Date(c(
"2025-01-01", # Jour de l'An
"2025-04-21", # Lundi de Pâques
"2025-05-01", # Fête du Travail
"2025-05-08", # Armistice
"2025-05-29", # Ascension
"2025-06-09", # Lundi de Pentecôte
"2025-07-14", # Fête Nationale
"2025-08-15", # Assomption
"2025-11-01", # Toussaint
"2025-11-11", # Armistice
"2025-12-25" # Noël
))
names(zd)
zd
dim(zd)
unique(zd$type_arret)
filtered_crosscheck = zd |> filter(!type_arret %in% c('Arrêt de bus','Station de téléphérique'))
dim(filtered_crosscheck) == dim(zd_railway)
dim(filtered_crosscheck)
dim(zd_railway)
filtered_crosscheck = zd |> filter(!type_arret %in% c('Arrêt de bus'))
dim(filtered_crosscheck)
filtered_crosscheck = zd |> filter(!type_arret %in% c('Arrêt de bus'))
dim(filtered_crosscheck)
dim(zd_railway)
unique(zd_railway$type_arret)
unique(zd_railway$type_arret)
zd_railway |> count(type_arret)
unique_stations = unique(val_grouped$ID_REFA_LDA)
unique_stations
length(unique_stations)
unique_stations = val_grouped |> head(150000) |> pull(ID_REFA_LDA) |> unique()
length(unique_stations)
val_2018_first$ID_REFA_LDA
length(val_2018_first$ID_REFA_LDA)
length(val_2018_second$ID_REFA_LDA)
length(val_2020_second$ID_REFA_LDA)
length(unique(val_2020_second$ID_REFA_LDA))
zd
zd <- st_read("data/REF_ZdA/PL_ZDL_R_11-11-2025.shp" )
zd
zf_clean <- zd %>%
mutate(area = st_area(geometry)) %>%     # compute geometry area
group_by(idrefa_lda) %>%                 # group by duplicated ID
slice_max(order_by = area, n = 1, with_ties = FALSE) %>%
ungroup() %>%
select(-area)                             # optional: remove temp column
zd_clean
zd_clean <- zd %>%
mutate(area = st_area(geometry)) %>%     # compute geometry area
group_by(idrefa_lda) %>%                 # group by duplicated ID
slice_max(order_by = area, n = 1, with_ties = FALSE) %>%
ungroup() %>%
select(-area)                             # optional: remove temp column
zd_clean
zd
dim(zd)
zd_clean <- zd %>%
mutate(area = st_area(geometry)) %>%     # compute geometry area
group_by(idrefa_lda) %>%                 # group by duplicated ID
slice_max(order_by = area, n = 1, with_ties = FALSE) %>%
ungroup() %>%
select(-area)                             # optional: remove temp column
zd_clean
zd_clean |>   select(-id_refa)
count(zd_clean$type_arret)
count(zd_clean$type_arret)
zdclean |> count(zd_clean$type_arret)
zdclean |> count(type_arret)
zd_clean |> count(type_arret)
unique_lda = unique(val_grouped$ID_REFA_LDA)
names(zd_clean)
unique_lda = unique(val_grouped$ID_REFA_LDA)
unique_lda
zd_clean_filtered |> filter(id_refa %in% unique_lda)
zd_clean_filtered = zd_clean |> filter(id_refa %in% unique_lda)
zd_clean_filtered |> count(type_arret)
zd_clean_filtered
names(zd_clean)
names(zd_clean)
zd_clean
zd_clean_filtered = zd_clean |> filter(idrefa_lda %in% unique_lda)
zd_clean_filtered |> count(type_arret)
zd_clean
zd
dim(zd)
unique(zd$type_arret)
zd_clean = zd |> filter(!type_arret %in% c('Arrêt de bus','Arrêt de tram'))
dim(zd_clean)
zd_clean = zd |> filter(!type_arret %in% c('Arrêt de bus','Arrêt de tram'))
unique_lda = unique(val_grouped$ID_REFA_LDA)
length(unique_lda)
length(unique_lda)
length(unique(zd_clean$type_arret))
length(zd_clean$type_arret)
unique_lda = unique(val_grouped$ID_REFA_LDA)
unique_lda = unique(val_grouped$ID_REFA_LDA)
dim(unique(zd$type_arret))
all(zd_clean$idrefa_lda %in% unique_lda)
all( unique_lda %in% zd_clean$idrefa_lda)
missing_in_lda <- zd_clean |>
filter(!(unique_lda %in% idrefa_lda))
zd <- st_read("data/REF_ZdA/PL_ZDL_R_11-11-2025.shp" )
zd_clean = zd |> filter(!type_arret %in% c('Arrêt de bus','Arrêt de tram'))
all( unique_lda %in% zd_clean$idrefa_lda)
col_spec <- cols(.default = "c")
val_2025_first <- read_csv2("data/validations-reseau-ferre-nombre-validations-par-jour-1er-trimestre.csv", col_types = col_spec)
val_2025_second <- read_csv2("data/validations-reseau-ferre-nombre-validations-par-jour-2eme-trimestre.csv", col_types = col_spec)
val_2018_first <- read_delim("data/data-rf-2018/2018_S1_NB_FER.txt", delim = "\t", col_types = col_spec)
val_2018_second <- read_delim("data/data-rf-2018/2018_S2_NB_FER.txt", delim = "\t",col_types = col_spec)
val_2019_first <- read_delim("data/data-rf-2019/2019_S1_NB_FER.txt", delim = "\t",col_types = col_spec)
val_2019_second <- read_delim("data/data-rf-2019/2019_S2_NB_FER.txt", delim = "\t",col_types = col_spec)
val_2020_first <- read_delim("data/data-rf-2020/2020_S1_NB_FER.txt", delim = "\t",col_types = col_spec)
val_2020_second <- read_delim("data/data-rf-2020/2020_S2_NB_FER.txt", delim = "\t",col_types = col_spec)
val_2021_first <- read_delim("data/data-rf-2021/2021_S1_NB_FER.txt", delim = "\t", col_types = col_spec)
val_2021_second <- read_delim("data/data-rf-2021/2021_S2_NB_FER.txt", delim = "\t", col_types = col_spec)
val_2022_first <- read_delim("data/data-rf-2022/2022_S1_NB_FER.txt", delim = "\t", col_types = col_spec)
val_2022_second <- read_delim("data/data-rf-2022/2022_S2_NB_FER.txt", delim = ";", col_types = col_spec)
val_2023_first <- read_delim("data/data-rf-2023/2023_S1_NB_FER.txt", delim = "\t", col_types = col_spec)
val_2023_second <- read_delim("data/data-rf-2023/2023_S2_NB_FER.txt", delim = "\t", locale = locale(encoding = "UTF-16"), col_types = col_spec)
val_2024_first <- read_delim("data/data-rf-2024/2024_S1_NB_FER.txt", delim = "\t", col_types = col_spec)
val_merged <- bind_rows(
val_2018_first,
val_2018_second,
val_2019_first,
val_2019_second,
val_2020_first,
val_2020_second,
val_2021_first,
val_2021_second,
val_2022_first,
val_2022_second,
val_2023_first,
val_2023_second,
val_2024_first,
# val_2025_first,
# val_2025_second
)
val_merged <- val_merged |> na.omit()
val_merged <- val_merged %>%
mutate(JOUR = parse_date_time(JOUR, orders = c("ymd", "mdy", "dmy")))
val_merged$NB_VALD = as.integer(val_merged$NB_VALD)
val_merged_cast <- val_merged %>% mutate(ID_REFA_LDA = sub("\\.0$", "", ID_REFA_LDA))
unique(val_merged_cast$ID_REFA_LDA)
val_grouped = val_merged_cast |> group_by(ID_REFA_LDA,JOUR,CATEGORIE_TITRE) |> summarise(NB_VALD = sum(NB_VALD))
val_grouped
write_parquet(val_grouped, "validations.parquet")
zd <- st_read("data/REF_ZdA/PL_ZDL_R_11-11-2025.shp" )
unique_stations = unique(val_grouped$ID_REFA_LDA)
length(unique_stations)
names(zd)
dim(zd)
unique(zd$type_arret)
zd_clean = zd |> filter(!type_arret %in% c('Arrêt de bus','Arrêt de tram'))
unique_lda = unique(val_grouped$ID_REFA_LDA)
all( unique_lda %in% zd_clean$idrefa_lda)
all( unique_lda %in% zd_clean$idrefa_lda)
col_spec <- cols(.default = "c")
val_2018_first <- read_delim("data/data-rf-2018/2018_S1_NB_FER.txt", delim = "\t", col_types = col_spec)
val_2018_second <- read_delim("data/data-rf-2018/2018_S2_NB_FER.txt", delim = "\t",col_types = col_spec)
val_2019_first <- read_delim("data/data-rf-2019/2019_S1_NB_FER.txt", delim = "\t",col_types = col_spec)
val_2019_second <- read_delim("data/data-rf-2019/2019_S2_NB_FER.txt", delim = "\t",col_types = col_spec)
val_2020_first <- read_delim("data/data-rf-2020/2020_S1_NB_FER.txt", delim = "\t",col_types = col_spec)
val_2020_second <- read_delim("data/data-rf-2020/2020_S2_NB_FER.txt", delim = "\t",col_types = col_spec)
val_2021_first <- read_delim("data/data-rf-2021/2021_S1_NB_FER.txt", delim = "\t", col_types = col_spec)
val_2021_second <- read_delim("data/data-rf-2021/2021_S2_NB_FER.txt", delim = "\t", col_types = col_spec)
val_2022_first <- read_delim("data/data-rf-2022/2022_S1_NB_FER.txt", delim = "\t", col_types = col_spec)
val_2022_second <- read_delim("data/data-rf-2022/2022_S2_NB_FER.txt", delim = ";", col_types = col_spec)
val_2023_first <- read_delim("data/data-rf-2023/2023_S1_NB_FER.txt", delim = "\t", col_types = col_spec)
val_2023_second <- read_delim("data/data-rf-2023/2023_S2_NB_FER.txt", delim = "\t", locale = locale(encoding = "UTF-16"), col_types = col_spec)
val_2024_first <- read_delim("data/data-rf-2024/2024_S1_NB_FER.txt", delim = "\t", col_types = col_spec)
val_2023_second <- rename(val_2023_second, ID_REFA_LDA = ID_ZDC)
val_2023_first <- rename(val_2023_first, ID_REFA_LDA = lda)
val_2024_first <- rename(val_2024_first, ID_REFA_LDA = ID_ZDC)
val_2022_second <- rename(val_2022_second, ID_REFA_LDA = lda)
val_merged <- bind_rows(
val_2018_first,
val_2018_second,
val_2019_first,
val_2019_second,
val_2020_first,
val_2020_second,
val_2021_first,
val_2021_second,
val_2022_first,
val_2022_second,
val_2023_first,
val_2023_second,
val_2024_first,
)
val_merged <- val_merged |> na.omit()
val_merged <- val_merged %>%
mutate(JOUR = parse_date_time(JOUR, orders = c("ymd", "mdy", "dmy")))
val_merged$NB_VALD = as.integer(val_merged$NB_VALD)
val_merged_cast <- val_merged %>% mutate(ID_REFA_LDA = sub("\\.0$", "", ID_REFA_LDA))
unique(val_merged_cast$ID_REFA_LDA)
val_grouped = val_merged_cast |> group_by(ID_REFA_LDA,JOUR,CATEGORIE_TITRE) |> summarise(NB_VALD = sum(NB_VALD))
val_grouped
write_parquet(val_grouped, "validations.parquet")
zd <- st_read("data/REF_ZdA/PL_ZDL_R_11-11-2025.shp" )
unique_stations = unique(val_grouped$ID_REFA_LDA)
length(unique_stations)
names(zd)
dim(zd)
unique(zd$type_arret)
zd_clean
dim(zd_clean)
dim(zd_clean)
zd_clean_only_val_stations = zd_clean |> filter(idrefa_lda %in% unique_lda)
dim(zd_clean_only_val_stations)
dim(zd_clean)
names(zd_clean)
unique_lda
#get the stations of all validations
unique_lda = unique(val_grouped$ID_REFA_LDA)
#Crosscheck to see if every station contained in validations, still is available on ZoneDeArret
all( unique_lda %in% zd_clean$idrefa_lda)
unique_lda
#Crosscheck to see if every station contained in validations, still is available on ZoneDeArret
all( unique_lda %in% zd_clean$idrefa_lda)
library(readr)
library(dplyr)
library(ggplot2)
library(lubridate )
library(sf)
library(arrow)
col_spec <- cols(.default = "c")
val_2018_first <- read_delim("data/data-rf-2018/2018_S1_NB_FER.txt", delim = "\t", col_types = col_spec)
val_2018_second <- read_delim("data/data-rf-2018/2018_S2_NB_FER.txt", delim = "\t",col_types = col_spec)
val_2019_first <- read_delim("data/data-rf-2019/2019_S1_NB_FER.txt", delim = "\t",col_types = col_spec)
val_2019_second <- read_delim("data/data-rf-2019/2019_S2_NB_FER.txt", delim = "\t",col_types = col_spec)
val_2020_first <- read_delim("data/data-rf-2020/2020_S1_NB_FER.txt", delim = "\t",col_types = col_spec)
val_2020_second <- read_delim("data/data-rf-2020/2020_S2_NB_FER.txt", delim = "\t",col_types = col_spec)
val_2021_first <- read_delim("data/data-rf-2021/2021_S1_NB_FER.txt", delim = "\t", col_types = col_spec)
val_2021_second <- read_delim("data/data-rf-2021/2021_S2_NB_FER.txt", delim = "\t", col_types = col_spec)
val_2022_first <- read_delim("data/data-rf-2022/2022_S1_NB_FER.txt", delim = "\t", col_types = col_spec)
val_2022_second <- read_delim("data/data-rf-2022/2022_S2_NB_FER.txt", delim = ";", col_types = col_spec)
val_2023_first <- read_delim("data/data-rf-2023/2023_S1_NB_FER.txt", delim = "\t", col_types = col_spec)
val_2023_second <- read_delim("data/data-rf-2023/2023_S2_NB_FER.txt", delim = "\t", locale = locale(encoding = "UTF-16"), col_types = col_spec)
val_2024_first <- read_delim("data/data-rf-2024/2024_S1_NB_FER.txt", delim = "\t", col_types = col_spec)
val_2023_second <- rename(val_2023_second, ID_REFA_LDA = ID_ZDC)
val_2023_first <- rename(val_2023_first, ID_REFA_LDA = lda)
val_2024_first <- rename(val_2024_first, ID_REFA_LDA = ID_ZDC)
val_2022_second <- rename(val_2022_second, ID_REFA_LDA = lda)
val_merged <- bind_rows(
val_2018_first,
val_2018_second,
val_2019_first,
val_2019_second,
val_2020_first,
val_2020_second,
val_2021_first,
val_2021_second,
val_2022_first,
val_2022_second,
val_2023_first,
val_2023_second,
val_2024_first,
)
val_merged <- val_merged |> na.omit()
val_merged <- val_merged %>%
mutate(JOUR = parse_date_time(JOUR, orders = c("ymd", "mdy", "dmy")))
val_merged$NB_VALD = as.integer(val_merged$NB_VALD)
val_merged_cast <- val_merged %>% mutate(ID_REFA_LDA = sub("\\.0$", "", ID_REFA_LDA))
val_grouped = val_merged_cast |> group_by(ID_REFA_LDA,JOUR,CATEGORIE_TITRE) |> summarise(NB_VALD = sum(NB_VALD))
write_parquet(val_grouped, "validations.parquet")
#load zone de arret
zd <- st_read("data/REF_ZdA/PL_ZDL_R_11-11-2025.shp" )
#The documentation available at the official portal
#states that Arret debus and Arret de tram are not contained in the validation files above loaded
zd_clean = zd |> filter(!type_arret %in% c('Arrêt de bus','Arrêt de tram'))
#get the stations of all validations
unique_lda = unique(val_grouped$ID_REFA_LDA)
unique_lda
#Crosscheck to see if every station contained in validations, still is available on ZoneDeArret
all( unique_lda %in% zd_clean$idrefa_lda)
len(unique_lda)
length(unique_lda)
length(idrefa_lda)
length(zd_clean$idrefa_lda)
unique_lda = unique(val_grouped$ID_REFA_LDA)
#load zone de arret
zd <- st_read("data/REF_ZdA/PL_ZDL_R_11-11-2025.shp" )
#The documentation available at the official portal
#states that Arret debus and Arret de tram are not contained in the validation files above loaded
zd_clean = zd |> filter(!type_arret %in% c('Arrêt de bus','Arrêt de tram'))
#get the stations of all validations
unique_lda = unique(val_grouped$ID_REFA_LDA)
filtered = zd_clean |> filter(!idrefa_lda in unique_lda )
filtered = zd_clean |> filter(!idrefa_lda %in% unique_lda )
filtered
dim(filtered)
filtered = zd_clean |> filter(!unique_lda %in% idrefa_lda )
unique_lda
filtered <- setdiff(unique_lda, zd_clean$idrefa_lda)
dim(filtered)
filtered
